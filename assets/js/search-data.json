{
  
    
        "post0": {
            "title": "Title",
            "content": "!pip install fastai -Uqqq . |████████████████████████████████| 194kB 5.6MB/s |██████████████████████ | 534.3MB 1.5MB/s eta 0:02:47 . from scipy.io import loadmat from scipy.ndimage import gaussian_filter from fastai.vision.all import * . from google.colab import drive drive.mount(&#39;/content/drive&#39;) . Mounted at /content/drive . Path(&quot;./drive/MyDrive/data/mall&quot;).ls() . (#2) [Path(&#39;drive/MyDrive/data/mall/mall_gt.mat&#39;),Path(&#39;drive/MyDrive/data/mall/frames&#39;)] . !cp -r drive/MyDrive/data/mall /mall/ . labels = loadmat(&#39;mall/mall_gt.mat&#39;)[&#39;frame&#39;][0] . label = labels[0] # extract GT for first frame ground_truth = (label[0][0][0]) # GT array ground_truth.shape . (29, 2) . ground_truth[:3] . array([[126.77986348, 60.70477816], [116.95051195, 47.59897611], [175.10750853, 44.3225256 ]]) . def generate_label(label_info, image_shape=(480,640)): &quot;Generate a density map based on objects positions&quot; # create an empty density map label = np.zeros(image_shape, dtype=np.float32) # loop over objects positions and marked them with 100 on a label for x, y, *_ in label_info: if y &lt; image_shape[0] and x &lt; image_shape[1]: label[int(y)][int(x)] = 100 # apply a convolution with a Gaussian kernel # label = gaussian_filter(label, sigma=(1, 1), order=0) return label . l = generate_label(ground_truth) l.shape . (480, 640) . l.sum() . 2900.0 . class TensorDMap(TensorImageBase): _show_args = {&#39;alpha&#39;:0.5, &#39;cmap&#39;:&#39;hot&#39;} def show(self, ctx=None, **kwargs): return show_image(self, ctx=ctx, title=str(array(self).sum()),**{**self._show_args, **kwargs}) TensorDMap._tensor_cls = TensorDMap . # class DMap(PILBase): # _open_args,_show_args = {&#39;mode&#39;:&#39;L&#39;},{&#39;alpha&#39;:0.5, &#39;cmap&#39;:&#39;hot&#39;} # def show(self, ctx=None, **kwargs): # x = array(self).astype(&#39;float&#39;) # onvert to float for next step # x = gaussian_filter(x, sigma=(1, 1), order=0) # create density map # ax = plt.imshow(x, **self._show_args); # return ax # # DMap._tensor_cls = TensorDMap . def get_lbl(fn): indx = int(re.findall(&#39;.+/seq_( d+).jpg&#39;, str(fn))[0])-1 # extract indx from fn lbl = labels[indx] return generate_label(lbl[0][0][0], (480,640)) . class DMap(PILBase): _open_args,_show_args = {&#39;mode&#39;:&#39;L&#39;},{&#39;alpha&#39;:0.5, &#39;cmap&#39;:&#39;hot&#39;} @classmethod def create(cls, fn): if isinstance(fn,ndarray): l = fn else: l = get_lbl(fn) l = gaussian_filter(l, sigma=(4, 4), order=0) return cls(Image.fromarray(l)) def show(self, ctx=None, **kwargs): ax = plt.imshow(array(self), **self._show_args); return ax # DMap._tensor_cls = TensorDMap . class DMap(PILBase): _open_args,_show_args = {&#39;mode&#39;:&#39;L&#39;},{&#39;alpha&#39;:0.5, &#39;cmap&#39;:&#39;hot&#39;} @classmethod def create(cls, fn): if isinstance(fn,ndarray): l = fn else: l = get_lbl(fn) l = gaussian_filter(l, sigma=(4, 4), order=0) return cls(Image.fromarray(l)) def show(self, ctx=None, **kwargs): ax = show_image(array(self), title=str(array(self).sum()), ctx=ctx, **self._show_args); return ax DMap._tensor_cls = TensorDMap . dm = DMap.create(l) dm.show(); . fn = &#39;mall/frames/seq_000001.jpg&#39; . dm = DMap.create(fn) dm.show(); . type(dm) . __main__.DMap . img = PILImage.create(fn) ax = show_image(img,figsize=(12,6)) dm.show(ctx=ax); . tup = (img, dm) rtup = RandomCrop(224)(tup) x, y = rtup x.shape, y.shape . ((224, 224), (224, 224)) . ax = x.show() y.show(ctx=ax); . files = sorted(get_image_files(&#39;mall/frames/&#39;)) len(files) . 2000 . dset = Datasets(files, [[PILImage.create], [DMap.create]], splits=[list(range(800)), list(range(800,1000))]) . dset[0] . (PILImage mode=RGB size=640x480, DMap mode=F size=640x480) . @ToTensor def encodes(self, o:DMap): return o._tensor_cls(image2tensor(o)) . dls = dset.dataloaders(bs=6, after_item=[RandomCrop(224), ToTensor], after_batch=[IntToFloatTensor, #Normalize.from_stats(*imagenet_stats) ], ) . b = dls.one_batch() b[0].shape, b[1].shape . (torch.Size([6, 3, 224, 224]), torch.Size([6, 1, 224, 224])) . dls.show_batch() . i=1 img, targ = b[0][i], b[1][i] . (b[0][i]).max() . TensorImage(0.7882, device=&#39;cuda:0&#39;) . IntToFloatTensor()(ToTensor()(PILImage.create(fn))).max() . TensorImage(1.) . show_image(img); . (targ).sum() . TensorDMap(404.1049, device=&#39;cuda:0&#39;) . dls = dset.dataloaders(bs=64, after_item=[RandomCrop(160), ToTensor], after_batch=[IntToFloatTensor, Normalize.from_stats(*imagenet_stats)], ) . dls.show_batch() . m = resnet34(pretrained=True) m = nn.Sequential(*list(m.children())[:-2]) unet = DynamicUnet(m, 1, (160, 160)) . learn = Learner(dls, unet, loss_func=MSELossFlat(), metrics=mae) . learn.fit(15, 1e-3) . epoch train_loss valid_loss mae time . 0 | 364.625336 | 0.076474 | 0.220978 | 00:17 | . 1 | 160.328506 | 0.012469 | 0.051903 | 00:17 | . 2 | 93.542328 | 0.013273 | 0.050194 | 00:17 | . 3 | 61.106697 | 0.011985 | 0.043798 | 00:17 | . 4 | 42.381104 | 0.012528 | 0.044669 | 00:17 | . 5 | 30.479683 | 0.011600 | 0.039887 | 00:17 | . 6 | 22.447672 | 0.011438 | 0.039839 | 00:17 | . 7 | 16.805000 | 0.011068 | 0.038806 | 00:18 | . 8 | 12.728518 | 0.010900 | 0.038440 | 00:17 | . 9 | 9.723621 | 0.010724 | 0.043080 | 00:17 | . 10 | 7.475395 | 0.010603 | 0.039847 | 00:17 | . 11 | 5.774604 | 0.010603 | 0.039077 | 00:17 | . 12 | 4.477199 | 0.010586 | 0.037199 | 00:17 | . 13 | 3.481197 | 0.010343 | 0.038050 | 00:17 | . 14 | 2.712719 | 0.010341 | 0.036873 | 00:17 | . learn.unfreeze(); learn.fit_one_cycle(30, slice(1e-6,1e-4)) . epoch train_loss valid_loss mae time . 0 | 0.002643 | 0.005449 | 0.024402 | 00:17 | . 1 | 0.002689 | 0.005466 | 0.024666 | 00:17 | . 2 | 0.002626 | 0.005492 | 0.024797 | 00:17 | . 3 | 0.002663 | 0.005415 | 0.024323 | 00:17 | . 4 | 0.002688 | 0.005589 | 0.026793 | 00:17 | . 5 | 0.002718 | 0.005463 | 0.025760 | 00:17 | . 6 | 0.002718 | 0.005386 | 0.024230 | 00:17 | . 7 | 0.002705 | 0.005675 | 0.025816 | 00:17 | . 8 | 0.002694 | 0.005385 | 0.024171 | 00:17 | . 9 | 0.002730 | 0.005455 | 0.024403 | 00:17 | . 10 | 0.002763 | 0.005408 | 0.024851 | 00:17 | . 11 | 0.002742 | 0.005353 | 0.025261 | 00:17 | . 12 | 0.002694 | 0.005364 | 0.024213 | 00:17 | . 13 | 0.002673 | 0.005330 | 0.023750 | 00:17 | . 14 | 0.002650 | 0.005454 | 0.026302 | 00:17 | . 15 | 0.002657 | 0.005347 | 0.022812 | 00:17 | . 16 | 0.002637 | 0.005313 | 0.023228 | 00:17 | . 17 | 0.002616 | 0.005281 | 0.022956 | 00:17 | . 18 | 0.002601 | 0.005336 | 0.023661 | 00:17 | . 19 | 0.002579 | 0.005341 | 0.023542 | 00:17 | . 20 | 0.002565 | 0.005293 | 0.023266 | 00:17 | . 21 | 0.002561 | 0.005328 | 0.023592 | 00:17 | . 22 | 0.002526 | 0.005345 | 0.026038 | 00:17 | . 23 | 0.002527 | 0.005238 | 0.022729 | 00:17 | . 24 | 0.002511 | 0.005319 | 0.023967 | 00:16 | . 25 | 0.002551 | 0.005258 | 0.023035 | 00:17 | . 26 | 0.002583 | 0.005250 | 0.023316 | 00:17 | . 27 | 0.002576 | 0.005238 | 0.022867 | 00:17 | . 28 | 0.002572 | 0.005251 | 0.023012 | 00:17 | . 29 | 0.002544 | 0.005254 | 0.023005 | 00:17 | . learn.show_results(0) . files[1000] . Path(&#39;mall/frames/seq_001001.jpg&#39;) . PILImage.create(files[1500]) . img, mask = RandomCrop(160)((PILImage.create(files[1500]), DMap.create(files[1500]))) ax = img.show(); mask.show(ctx=ax); . tdl = dls.test_dl([img]) . out, _ = learn.get_preds(dl=tdl) out.shape . torch.Size([1, 1, 160, 160]) . out.sum() . TensorImage(714.9376) . ax = img.show(); TensorDMap(out.squeeze()).show(ctx=ax); . out = out.squeeze() . out = torch.where(out&gt;0, out, torch.zeros_like(out)) . ax = img.show(); TensorDMap(out.squeeze()).show(ctx=ax); . dls.valid.show_batch() . with dls.valid_ds.set_split_idx(0): dls.valid.show_batch() . with dls.valid_ds.set_split_idx(0): learn.show_results(alpha=.35) . learn.save(&quot;crowd-res34-160px&quot;) . Path(&#39;models/crowd-res34-160px.pth&#39;) . with dls.valid_ds.set_split_idx(0): preds = learn.get_preds() . im, dn = preds[0][0], preds[0][1] . RandomCrop(160)(dls.valid_ds[0][0]).show() . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f05c0730350&gt; . show_image(im) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f05c07549d0&gt; . show_image(dn) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f050db76050&gt; .",
            "url": "https://feras-oughali.github.io/blog/2021/04/25/blog_density_map_valid.html",
            "relUrl": "/2021/04/25/blog_density_map_valid.html",
            "date": " • Apr 25, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://feras-oughali.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://feras-oughali.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://feras-oughali.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://feras-oughali.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}